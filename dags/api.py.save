import requests
from airflow import DAG
from airflow.operators.python_operator import PythonOperator
from datetime import datetime, timedelta

headers = {"Content-Type": "application/json; charset=utf-8", "x-access-token": 'eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJlbWFpbCI6Im1hcnRpbmtyZWNlazlAZ21haWwuY29tIiwiaWQiOjE0NTIsIm5hbWUiOm51bGwsInN1cm5hbWUiOm51bGwsImlhdCI6MTY2NDM1Nzc3NCwiZXhwIjoxMTY2NDM1Nzc3NCwiaXNzIjoiZ29sZW1pbyIsImp0aSI6IjU1MWMxM2I2LTZiYzktNDg4My05NTNmLTA0MWRkNmYwZjVjOCJ9.jss-5Fw6bCRxVWZuzm4Og2D53afsmcAyDxkxMWCdik'}

# Define the DAG
dag = DAG(
    dag_id='get_file_from_endpoint',
    start_date=datetime(2023, 3, 12),
    schedule_interval='@daily',
    catchup=False,
)

# Define a Python function to check if the endpoint is available
def check_endpoint():
    url = 'https://api.golemio.cz/v2/parking/measurements?source=TSK&limit=10000'
    response = requests.get(url,headers=headers)
    if response.status_code != 200:
        raise ValueError('Endpoint not available')

# Define a Python function to download the file
def download_file():
    url = 'https://api.golemio.cz/v2/parking/measurements?source=TSK&limit=10000'
    response = requests.get(url, stream=True)
    with open('/tmp/myfile.csv', 'wb') as f:
        for chunk in response.iter_content(chunk_size=1024):
            if chunk:
                f.write(chunk)

# Define a task to check if the endpoint is available
check_endpoint_task = PythonOperator(
    task_id='check_endpoint',
    python_callable=check_endpoint,
    dag=dag,
)

# Define a task to download the file
download_file_task = PythonOperator(
    task_id='download_file',
    python_callable=download_file,
    dag=dag,
)

# Set task dependencies
check_endpoint_task >> download_file_task
